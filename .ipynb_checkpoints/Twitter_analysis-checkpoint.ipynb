{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0      1       2       3        4       5        6    \\\n",
      "0            Air  India  flight     814  skidded     off      the   \n",
      "1            Air  India       �       �        �       s      San   \n",
      "2    @airindiain     In     Air   India   flight       I  noticed   \n",
      "3  @SushmaSwaraj    Air   India      AI      966   stuck       in   \n",
      "4        Special    Air   India  flight  ferries  bodies       of   \n",
      "\n",
      "           7          8        9    ...    283   284   285   286   287   288  \\\n",
      "0       runway      while  landing  ...   None  None  None  None  None  None   \n",
      "1    Francisco     Flight  Delayed  ...   None  None  None  None  None  None   \n",
      "2          tht  breakfast       is  ...   None  None  None  None  None  None   \n",
      "3       Jeddah    airport     None  ...   None  None  None  None  None  None   \n",
      "4  Uttarakhand        bus    crash  ...   None  None  None  None  None  None   \n",
      "\n",
      "    289   290   291   292  \n",
      "0  None  None  None  None  \n",
      "1  None  None  None  None  \n",
      "2  None  None  None  None  \n",
      "3  None  None  None  None  \n",
      "4  None  None  None  None  \n",
      "\n",
      "[5 rows x 293 columns]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "reader=csv.reader(open('airindia_new.csv','rb'))\n",
    "tweets=set()\n",
    "processed_tweets=[]\n",
    "for row in reader:\n",
    "    tweet=[]\n",
    "    tweet.append(list(row[0].split(';'))[4])\n",
    "    #print tweet\n",
    "    tweets.update(set(tweet))\n",
    "for tweet in tweets:\n",
    "    processed_tweets.append(preprocess(tweet)[1:])\n",
    "import pandas as pd\n",
    "tweets_df=pd.DataFrame(processed_tweets)\n",
    "print tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For cleaning tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RT', '@marcobonzanini', ':', 'just', 'an', 'example', '!', ':D', 'http://example.com', '#NLP']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    " \n",
    "emoticons_str = r\"\"\"\n",
    "    (?:\n",
    "        [:=;] # Eyes\n",
    "        [oO\\-]? # Nose (optional)\n",
    "        [D\\)\\]\\(\\]/\\\\OpP] # Mouth\n",
    "    )\"\"\"\n",
    " \n",
    "regex_str = [\n",
    "    emoticons_str,\n",
    "    r'<[^>]+>', # HTML tags\n",
    "    r'(?:@[\\w_]+)', # @-mentions\n",
    "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
    "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
    " \n",
    "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
    "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
    "    r'(?:[\\w_]+)', # other words\n",
    "    r'(?:\\S)' # anything else\n",
    "]\n",
    "    \n",
    "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
    "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
    " \n",
    "def tokenize(s):\n",
    "    return tokens_re.findall(s)\n",
    " \n",
    "def preprocess(s, lowercase=False):\n",
    "    tokens = tokenize(s)\n",
    "    if lowercase:\n",
    "        tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
    "    return tokens\n",
    " \n",
    "tweet = 'RT @marcobonzanini: just an example! :D http://example.com #NLP'\n",
    "print(preprocess(tweet))\n",
    "# ['RT', '@marcobonzanini', ':', 'just', 'an', 'example', '!', ':D', 'http://example.com', '#NLP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0      1       2       3        4       5        6   \\\n",
      "0            Air  India  flight     814  skidded     off      the   \n",
      "1            Air  India       �       �        �       s      San   \n",
      "2    @airindiain     In     Air   India   flight       I  noticed   \n",
      "3  @SushmaSwaraj    Air   India      AI      966   stuck       in   \n",
      "4        Special    Air   India  flight  ferries  bodies       of   \n",
      "\n",
      "            7          8        9   ...       19        20      21    22  \\\n",
      "0       runway      while  landing  ...   lights  suffered  damage     :   \n",
      "1    Francisco     Flight  Delayed  ...        .        tt       /     2   \n",
      "2          tht  breakfast       is  ...    given         .    This   may   \n",
      "3       Jeddah    airport     None  ...     None      None    None  None   \n",
      "4  Uttarakhand        bus    crash  ...        /        fb       /    08   \n",
      "\n",
      "       23    24        25    26    27    28  \n",
      "0     ANI     \"      None  None  None  None  \n",
      "1  xJyXhK     \"      None  None  None  None  \n",
      "2  create     a  security  risk     \"  None  \n",
      "3    None  None      None  None  None  None  \n",
      "4    RVgu     \"      None  None  None  None  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "reader=csv.reader(open('airindia_new.csv','rb'))\n",
    "tweets=set()\n",
    "processed_tweets=[]\n",
    "for row in reader:\n",
    "    tweet=[]\n",
    "    tweet.append(list(row[0].split(';'))[4])\n",
    "    #print tweet\n",
    "    tweets.update(set(tweet))\n",
    "for tweet in tweets:\n",
    "    processed_tweets.append(preprocess(tweet)[1:30]) #30 to control the number of columns\n",
    "import pandas as pd\n",
    "tweets_df=pd.DataFrame(processed_tweets)\n",
    "print tweets_df.head() #head() to print the first five row of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
